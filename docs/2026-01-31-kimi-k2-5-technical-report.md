# Kimi K2.5 技術レポート - マルチモーダルエージェントモデルの新時代

- **ソース:** [GitHub - MoonshotAI/Kimi-K2.5](https://github.com/MoonshotAI/Kimi-K2.5)
- **著者:** Moonshot AI
- **日付:** 2026年1月
- **種別:** 技術レポート
- **アーカイブ日:** 2026-01-31

---

## 概要

Moonshot AIが発表したKimi K2.5は、視覚と言語の理解を統合したネイティブマルチモーダルエージェントモデル。約15兆の混合視覚・テキストトークンで継続事前学習され、GPT-5.2、Claude Opus 4.5、Gemini 3 Proと肩を並べるパフォーマンスを示している。

## 主要な特徴

### 1. ネイティブマルチモーダリティ
視覚と言語のトークンで事前学習されており、視覚的知識、クロスモーダル推論、視覚入力に基づくエージェント的ツール使用に優れる。

### 2. ビジョンを使ったコーディング
UIデザインやビデオワークフローといった視覚仕様からコードを生成し、視覚データ処理のためのツールを自律的に編成できる。

### 3. Agent Swarm（エージェントスウォーム）
単一エージェントスケーリングから、自己指向型・協調型のスウォーム実行スキームへの移行。複雑なタスクを並列サブタスクに分解し、動的にインスタンス化されたドメイン固有のエージェントによって実行する。

## モデル仕様

| 項目 | 値 |
|------|-----|
| アーキテクチャ | Mixture-of-Experts (MoE) |
| 総パラメータ数 | 1T |
| アクティブパラメータ数 | 32B |
| レイヤー数 | 61（Denseレイヤー含む） |
| エキスパート数 | 384 |
| トークンごとに選択されるエキスパート | 8 |
| コンテキスト長 | 256K |
| ビジョンエンコーダ | MoonViT (400M params) |
| 語彙サイズ | 160K |

## ベンチマーク性能（抜粋）

### 推論・知識
- **AIME 2025:** 96.1（GPT-5.2: 100、Claude 4.5: 92.8）
- **GPQA-Diamond:** 87.6（GPT-5.2: 92.4、Claude 4.5: 87.0）
- **MMLU-Pro:** 87.1（Gemini 3 Pro: 90.1、Claude 4.5: 89.3）

### 画像・動画
- **MMMU-Pro:** 78.5（Gemini 3 Pro: 81.0、GPT-5.2: 79.5）
- **MathVision:** 84.2（Gemini 3 Pro: 86.1、GPT-5.2: 83.0）
- **OCRBench:** 92.3（GPT-5.2: 80.7、Claude 4.5: 86.5）
- **VideoMMMU:** 86.6（Gemini 3 Pro: 87.6、GPT-5.2: 85.9）

### コーディング
- **SWE-Bench Verified:** 76.8（Claude 4.5: 80.9、GPT-5.2: 80.0）
- **LiveCodeBench (v6):** 85.0（Gemini 3 Pro: 87.4、Claude 4.5: 82.2）

### エージェンティック検索
- **BrowseComp (Agent Swarm):** 78.4（他モデルは通常モードで60-65前後）
- **WideSearch (Agent Swarm):** 79.0 item-f1（通常モード: 72.7）

## Agent Swarmの革新性

従来のシングルエージェントアプローチと異なり、K2.5は複雑なタスクを自動的に分解し、専門化されたサブエージェントを動的に生成・協調させる。例えば：

- **BrowseComp:** メインエージェント最大15ステップ、サブエージェント最大100ステップ
- **WideSearch:** メイン・サブエージェント共に最大100ステップ

この手法により、単一エージェントモデルと比較して有意な性能向上を実現している。

## ネイティブINT4量子化

Kimi-K2-Thinkingと同じネイティブint4量子化手法を採用し、効率的なデプロイメントを実現。

## デプロイメント

以下の推論エンジンで動作を推奨：
- **vLLM**
- **SGLang**
- **KTransformers**

transformersの最小バージョン要件: 4.57.1

公式API: [https://platform.moonshot.ai](https://platform.moonshot.ai)（OpenAI/Anthropic互換API）

## ライセンス

Modified MIT Licenseでコードリポジトリとモデルウェイトの両方を公開。

---

## 解説・所感

Kimi K2.5は、オープンソースAIモデルとして極めて重要なマイルストーンである。以下の点で注目に値する：

### 1. 真のマルチモーダル統合
多くのモデルが後付けでビジョン機能を追加している中、K2.5は最初から視覚と言語を統合して学習している。これにより、UIデザインからコード生成といった実践的なタスクが可能になっている。

### 2. Agent Swarmという新パラダイム
単一の大型エージェントをスケールさせるのではなく、動的に専門化されたエージェント群を協調させるアプローチは、より人間的な問題解決手法に近い。BrowseCompやWideSearchでの性能向上がこの有効性を証明している。

### 3. オープンソースの競争力
GPT-5.2やClaude Opus 4.5といったクローズドソースモデルに匹敵する性能を、MITライセンスで公開している点は、AI民主化の観点から極めて重要。

### 4. 実用性重視の設計
256Kのコンテキスト長、INT4量子化対応、主要な推論エンジンサポートなど、実際にプロダクションで使えることを重視した設計になっている。

### 課題と今後の展望
- SWE-Benchシリーズでは若干Claude 4.5に劣る（70台後半 vs 80前後）
- Agent Swarmの詳細な実装や最適化手法はまだ明らかになっていない
- ビデオ入力機能は実験的で、公式APIのみサポート

それでも、K2.5はオープンソースAIの新たな基準を打ち立てたと言える。特に、Agent Swarmという概念が今後のAI開発にどのような影響を与えるか、注目していきたい。

---

**タグ:** #AI #MultiModal #MoE #AgentSwarm #OpenSource #Moonshot #Kimi #Benchmark
